{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n2\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[None, None]"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "d = {'a': 1, 'b':2}\n",
    "[print(d[key]) for key in d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk, path\n",
    "dic_csv = {}\n",
    "df_var = {} \n",
    "for root,d_names,f_names in walk(\"./data/\"):\n",
    "    for f in f_names:\n",
    "        filename = f.rsplit('.', 1)[0]\n",
    "        dic_csv[path.join(root, f)] = ('processed_' + filename) if ('processed' in root) else filename\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_df(dic):\n",
    "    for key in dic:\n",
    "        df_var[dic[key]] = pd.read_csv(key, delimiter=\";\")\n",
    "make_df(dic_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "      client_id  birth_number  district_id\n0             1        706213           18\n1             2        450204            1\n2             3        406009            1\n3             4        561201            5\n4             5        605703            5\n...         ...           ...          ...\n5364      13955        456030            1\n5365      13956        430406            1\n5366      13968        680413           61\n5367      13971        626019           67\n5368      13998        535812           74\n\n[5369 rows x 3 columns]\n"
    }
   ],
   "source": [
    "print(df_var['client'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(df, column):\n",
    "    list = df[column].unique().tolist()\n",
    "    dic = {}\n",
    "    for l in list:\n",
    "        dic[l] = df[df[column]==l]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_train_test(dic):\n",
    "    lis = [d for d in list(dic.values()) if ('test' in d or 'train' in d)]\n",
    "    train = []\n",
    "    test = []\n",
    "    names = []\n",
    "    for l in lis:\n",
    "        names.append(l.split(\"_\")[0])\n",
    "        if (l.split(\"_\")[1] == 'train'):\n",
    "            train.append(l)\n",
    "        else:\n",
    "            test.append(l)\n",
    "    names = list(set(names))\n",
    "    \n",
    "    for n in names:\n",
    "        t1 = [d for d in train if n in d][0]\n",
    "        t2 = [d for d in test if n in d][0]\n",
    "        \n",
    "        df_var[n] = pd.concat([df_var[t1],df_var[t2]])\n",
    "concat_train_test(dic_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary functions to process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def getDate(d):\n",
    "    year = 1900+int(str(d)[0:2])\n",
    "    month = int(str(d)[2:4])\n",
    "    gender = 'M' if (month < 50) else 'F'\n",
    "    month = month if (month < 50) else month - 50\n",
    "    day = int(str(d)[4:6])\n",
    "    return {'year': year, 'month': month, 'day': day, 'gender': gender}\n",
    "\n",
    "def getGender(df):\n",
    "    list = []\n",
    "    for row in df.itertuples(index = True):\n",
    "        d = getDate(row.birth_number)\n",
    "        birth_number = row.birth_number \n",
    "        if (d['gender'] == 'F'):\n",
    "            birth_number -= 5000\n",
    "        list.append([row.client_id, birth_number, d['gender'], row.district_id])\n",
    "    \n",
    "    return pd.DataFrame(list, columns=['client_id', 'birth_number', 'gender', 'district_id'])\n",
    "\n",
    "print(getGender(df_var['client']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range(df,min_year, max_year):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumns(df):\n",
    "    sum = 0\n",
    "    for key in df:\n",
    "        if not 'train' in key and not 'test' in key:\n",
    "            print('{} -> {}'.format(key, len(df_var[key].columns)))\n",
    "            print('{}\\n'.format(df_var[key].columns))\n",
    "\n",
    "            sum = sum + len(df_var[key].columns)\n",
    "    print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#credit in cash', 'collection from another bank', nan,'withdrawal in cash', 'remittance to another bank',\n",
    "#       'credit card withdrawal'\n",
    "\n",
    "def n_credit_cash(col):\n",
    "    return sum(col == 'credit in cash')\n",
    "\n",
    "def n_collection_from_another_bank(col):\n",
    "    return sum(col == 'collection from another bank')\n",
    "\n",
    "def n_withdrawal_in_cash(col):\n",
    "    return sum(col == 'withdrawal in cash')\n",
    "\n",
    "def n_remittance_to_another_bank(col):\n",
    "    return sum(col == 'remittance to another bank')\n",
    "\n",
    "def n_credit_card_withdrawal(col):\n",
    "    return sum(col == 'credit card withdrawal')\n",
    "\n",
    "def n_interest_credited(col):\n",
    "    return sum(col == 'none')\n",
    "\n",
    "\n",
    "\n",
    "def n_credit(col):\n",
    "    return sum(col == 'credit')\n",
    "\n",
    "def n_withdrawal(col):\n",
    "    return sum(col == 'withdrawal') + sum(col == 'withdrawal in cash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Merge():\n",
    "    # Copying information from dictonary into dataframes\n",
    "\n",
    "    client = df_var['client'].copy()\n",
    "    disp = df_var['disp'].copy()\n",
    "    card = df_var['card'].copy()\n",
    "    loan = df_var['loan'].copy()\n",
    "    account = df_var['account'].copy()\n",
    "    district = df_var['district'].copy()\n",
    "    card = card.rename({'type': 'card_type'}, axis=1)\n",
    "    disp = disp.rename({'type': 'disp_type'}, axis=1)\n",
    "\n",
    "    # Merging informations\n",
    "\n",
    "    merge1 = pd.merge(client, disp[disp['disp_type'] =='OWNER'], on ='client_id')\n",
    "    merge2 = pd.merge(merge1, account, on = 'account_id')\n",
    "    merge3 = pd.merge(merge2, card[['card_id', 'disp_id', 'card_type']], on = 'disp_id', how = 'left')\n",
    "    merge4 = pd.merge(merge3, district, left_on = 'district_id_x', right_on='code')\n",
    "    merge5 = pd.merge(loan, merge4, on = 'account_id')\n",
    "\n",
    "    # Dropping some columns\n",
    "    merge5.drop(['client_id', 'disp_id', 'disp_type', 'card_id', 'code'], axis = 1, inplace = True)\n",
    "\n",
    "    # Renaming columns\n",
    "    merge5.rename({\n",
    "        'date_x': 'loan_date', \n",
    "        'district_id_x': 'client_district', \n",
    "        'district_id_y': 'account_district',\n",
    "        'date_y': 'account_date'\n",
    "    }, axis = 1, inplace = True)\n",
    "\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    \n",
    "    # Processing transactions information \n",
    "\n",
    "    trans = df_var['trans'].copy()\n",
    "    trans = trans.rename({\n",
    "        'type': 'trans_type',\n",
    "        'date': 'trans_date', \n",
    "        'amount': 'trans_amount',\n",
    "        'balance': 'trans_balance'}, axis=1)\n",
    "    trans.sort_values(by = ['account_id', 'trans_date'])\n",
    "    trans.drop(['trans_id', 'k_symbol', 'account', 'bank'], axis=1, inplace = True)\n",
    "\n",
    "    #t = trans.groupby('account_id').tail(1)\n",
    "\n",
    "    # Merging trans with previous information\n",
    "\n",
    "    loan_info = pd.merge(merge5, trans, on = 'account_id')\n",
    "    loan_info.fillna('none', inplace = True)\n",
    "    #Columns that are not going to be changed\n",
    "    cols = loan_info.columns.difference(['trans_date', 'trans_amount', 'trans_balance', 'trans_type', 'operation'], sort = False).tolist()\n",
    "\n",
    "    # Group by operation\n",
    "\n",
    "    l = loan_info.groupby(by = cols, as_index = False).agg({\n",
    "                        'trans_date': ['min', 'max'],\n",
    "                        'trans_amount': ['min', 'max', 'mean', 'std', 'last'],\n",
    "                        'trans_balance': ['min', 'max', 'mean', 'std', 'last'],\n",
    "                        'trans_type':[n_credit, n_withdrawal],\n",
    "                        'operation':[n_credit_cash, n_collection_from_another_bank, \n",
    "                                    n_withdrawal_in_cash, n_remittance_to_another_bank,\n",
    "                                    n_credit_card_withdrawal, n_interest_credited]\n",
    "                    })\n",
    "\n",
    "    #Change columns name \n",
    "    l.columns = ['%s%s' % (level1, '_%s' % level2 if level2 else '') for level1, level2 in l.columns]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Save_CSV(df):\n",
    "    df.sort_values(by = ['loan_id'])\n",
    "    df.to_csv('loan_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db():\n",
    "    CSV_files = {'account': account, 'card': card_train, 'client': client, 'disp': disp, 'disctrict': district, 'loan': loan_train, 'trans': trans_train}\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    # Correr sÃ³ uma vez\n",
    "    if not os.path.exists('./database.db'):\n",
    "        for f in CSV_files:\n",
    "            CSV_files[f].to_sql(f, conn)\n",
    "    query = \"\"\"\n",
    "        SELECT loan_id, loan.account_id, status\n",
    "        FROM loan, account\n",
    "        WHERE loan.account_id == account.account_id\n",
    "        \"\"\"\n",
    "         \n",
    "    pd.read_sql_query(query, conn)\n",
    "    \n",
    "def getCorr(df, size=(11,9)):\n",
    "    corr = df.corr()\n",
    "    ax = plt.subplots(figsize=size)\n",
    "    ax = sns.heatmap(corr,  annot = True, linewidths=.1, mask = np.triu(corr), cmap='coolwarm')\n",
    "\n",
    "    def checkUniqueCategoricalVars():\n",
    "    for f in CSV_files:\n",
    "        print(\"{}:\\n {}\\n\\n\".format(f, CSV_files[f].select_dtypes(include=['object']).nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"results/DT_23-10.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.drop(a.columns.difference(['loan_id','prediction(status)']), 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.rename(columns={\"loan_id\": \"Id\", \"prediction(status)\": \"Predicted\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.round({'Predicted': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['Predicted'] = b.apply(lambda x: roundPred(x['Predicted']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundPred(x):\n",
    "    return 1 if (x >= 0) else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_info = pd.read_csv(\"results/DT_all_info.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b.to_csv('DT_all_info_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(b, df_all_info, on = 'Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = merge.assign(diff=merge['Predicted_x'] - merge['Predicted_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "loan_train_1 = loan_train.copy()\n",
    "for f in loan_train_1.columns:\n",
    "    if loan_train_1[f].dtype=='object': \n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(loan_train_1[f].values))\n",
    "        loan_train_1[f] = lbl.transform(list(loan_train_1[f].values))\n",
    "\n",
    "loan_test_1 = loan_test.copy()\n",
    "for f in loan_test_1.columns:\n",
    "    if loan_test_1[f].dtype=='object': \n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(loan_test_1[f].values))\n",
    "        loan_test_1[f] = lbl.transform(list(loan_test_1[f].values))\n",
    "\n",
    "X = loan_test_1.drop(columns='status')\n",
    "X_test = loan_train_1.drop(columns='status')\n",
    "y_test = loan_train_1['status'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "\n",
    "def find_best_params_kfold(model, X, y, param_grid, n_iter=10, n_splits=3):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    search = RandomizedSearchCV(model, param_grid, scoring=\"neg_mean_absolute_error\", n_jobs=-1, n_iter=n_iter, cv=kfold, verbose=0, random_state=0)\n",
    "    result = search.fit(X_test, y_test)\n",
    "    \n",
    "    report(result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    res = []\n",
    "    res_i = 0\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            res.append([np.multiply(results['mean_test_score'][candidate], -1), \n",
    "                        results['std_test_score'][candidate]])\n",
    "            for key in results['params'][candidate].keys():\n",
    "                res[res_i].append(results['params'][candidate][key])\n",
    "            res_i+=1\n",
    "    \n",
    "    columns = ['Mean absolute error', 'std'] + list(results['params'][candidate].keys())\n",
    "    display(pd.DataFrame(res, columns=columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_depth = range(2, 30, 1)\n",
    "min_samples_split = range(1, 10, 1)\n",
    "min_samples_leaf = range(1, 2, 1)\n",
    "\n",
    "param_grid = dict(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "X = loan_train.loc[:, loan_train.columns != 'status']\n",
    "y = loan_train.loc[:, loan_train.columns == 'status']\n",
    "find_best_params_kfold(DecisionTreeClassifier(random_state=0), X_test, y_test, param_grid, \n",
    "                       n_iter=50, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier_cart = DecisionTreeClassifier(max_depth=3, min_samples_split=4, min_samples_leaf = 1, random_state=0)\n",
    "classifier_cart = classifier_cart.fit(X_test, y_test)\n",
    "\n",
    "y_test_cart = classifier_cart.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_train.loc[:, loan_train.columns == 'status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;loans&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-17-b5b4f0975da4&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m&#39;object&#39;\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;loans&#39; is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = loans.copy()\n",
    "for f in df.columns:\n",
    "    if df[f].dtype=='object': \n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(df[f].values))\n",
    "        df[f] = lbl.transform(list(df[f].values))\n",
    "\n",
    "X= df.drop(columns='status')\n",
    "y = df['status'].copy()\n",
    "\n",
    "df_test = loans_test.copy()\n",
    "\n",
    "for f in df_test.columns:\n",
    "    if df_test[f].dtype=='object': \n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(df_test[f].values))\n",
    "        df_test[f] = lbl.transform(list(df_test[f].values))\n",
    "\n",
    "X_test = df_test.drop(columns='status')\n",
    "y_test = df_test['status'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "\n",
    "def find_best_params_kfold(model, X, y, param_grid, n_iter=10, n_splits=3):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    search = RandomizedSearchCV(model, param_grid, scoring=\"neg_mean_absolute_error\", n_jobs=-1, n_iter=n_iter, cv=kfold, verbose=0, random_state=0)\n",
    "    result = search.fit(X, y)\n",
    "    \n",
    "    report(result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    res = []\n",
    "    res_i = 0\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            res.append([np.multiply(results['mean_test_score'][candidate], -1), \n",
    "                        results['std_test_score'][candidate]])\n",
    "            for key in results['params'][candidate].keys():\n",
    "                res[res_i].append(results['params'][candidate][key])\n",
    "            res_i+=1\n",
    "    \n",
    "    columns = ['Mean absolute error', 'std'] + list(results['params'][candidate].keys())\n",
    "    display(pd.DataFrame(res, columns=columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validationScores(modelName, model, X, y, n_folds=10):\n",
    "    metrics = {'MAE': 'neg_mean_absolute_error', \n",
    "               'RMSE': 'neg_root_mean_squared_error'}\n",
    "    \n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "    scores = cross_validate(model, X, y, cv=kfold, scoring=metrics, n_jobs=-1)\n",
    "\n",
    "    # multiply by -1 because sklearn scoring metrics are negative\n",
    "    mean_mae_score = np.multiply(scores['test_MAE'], -1).mean()\n",
    "    std_mae_score = np.multiply(scores['test_MAE'], -1).std()\n",
    "    mean_rmse_score = np.multiply(scores['test_RMSE'], -1).mean()\n",
    "    std_rmse_score = np.multiply(scores['test_RMSE'], -1).std()\n",
    "\n",
    "    model_score = pd.DataFrame([[mean_mae_score, mean_rmse_score]], \n",
    "                             columns=['MAE', 'RMSE'], index=[modelName])\n",
    "    global models_mean_scores\n",
    "    models_mean_scores = models_mean_scores.append(model_score)\n",
    "\n",
    "    print(str(n_folds) + \" fold Cross validation scores for \" + modelName)\n",
    "    score_df = pd.DataFrame([[mean_mae_score, std_mae_score], \n",
    "                                  [mean_rmse_score, std_rmse_score]], \n",
    "                                 columns=['Mean score', 'std'], \n",
    "                                 index=['MAE', 'RMSE'])\n",
    "    display(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#\ttest_size = 0.30, random_state = 0)\n",
    "#from sklearn import tree\n",
    "\n",
    "#X_train = df.drop(columns='status')\n",
    "#y_train = loan['status'].copy()\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "#clf = clf.fit(X, y)\n",
    "\n",
    "#X_test = loan_test.drop(columns='status')\n",
    "#y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;X_test&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-21-f4ab32fa52be&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[0;32m----&gt; 1\u001b[0;31m \u001b[0mpredict_loan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m&#39;Id&#39;\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m&quot;loan_id&quot;\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;Predicted&#39;\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_loan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m&#39;loan_predict.csv&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;X_test&#39; is not defined"
     ]
    }
   ],
   "source": [
    "predict_loan = {'Id': X_test[\"loan_id\"], 'Predicted': y_test}\n",
    "df = pd.DataFrame(data=predict_loan)\n",
    "df.to_csv('loan_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_depth = range(2, 30, 1)\n",
    "min_samples_split = range(1, 10, 1)\n",
    "\n",
    "param_grid = dict(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "\n",
    "find_best_params_kfold(DecisionTreeClassifier(random_state=0), X, y, param_grid, \n",
    "                       n_iter=50, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;DecisionTreeClassifier&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-22-c9876b00811c&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[0;32m----&gt; 1\u001b[0;31m \u001b[0mclassifier_cart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclassifier_cart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_cart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test_cart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_cart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;DecisionTreeClassifier&#39; is not defined"
     ]
    }
   ],
   "source": [
    "classifier_cart = DecisionTreeClassifier(max_depth=2, min_samples_split=9, random_state=0)\n",
    "classifier_cart = classifier_cart.fit(X, y)\n",
    "\n",
    "y_test_cart = classifier_cart.predict(X_test)\n",
    "\n",
    "#df_pred = pd.DataFrame(data={'Id': X_test[\"loan_id\"], 'Predicted': y_test_cart})\n",
    "#df_pred.to_csv('loan_pred_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;classifier_cart&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-23-b57bb9215fb7&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[0;32m----&gt; 1\u001b[0;31m \u001b[0my_test_cart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_cart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#df_pred = pd.DataFrame(data={&#39;Id&#39;: X_test_owner[&quot;loan_id&quot;], &#39;Predicted&#39;: y_test_cart})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df_pred.to_csv(&#39;loan_pred_3.csv&#39;, index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test_cart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;classifier_cart&#39; is not defined"
     ]
    }
   ],
   "source": [
    "y_test_cart = classifier_cart.predict(X_test)\n",
    "#df_pred = pd.DataFrame(data={'Id': X_test_owner[\"loan_id\"], 'Predicted': y_test_cart})\n",
    "#df_pred.to_csv('loan_pred_3.csv', index=False)\n",
    "y_test_cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;regr_cart&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-24-fc074267940a&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 5\u001b[0;31m find_best_params_kfold(BaggingClassifier(base_estimator=regr_cart,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                         n_jobs=-1, random_state=0), \n\u001b[1;32m      7\u001b[0m                        X, y, param_grid, n_iter=30, n_splits=3)\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;regr_cart&#39; is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "n_estimators = range(50, 1000, 50)\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "find_best_params_kfold(BaggingClassifier(base_estimator=regr_cart,\n",
    "                                        n_jobs=-1, random_state=0), \n",
    "                       X, y, param_grid, n_iter=30, n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;X_test&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-25-edfa27cfc66c&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[0;32m----&gt; 1\u001b[0;31m \u001b[0mX_test_owner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m&#39;type&#39;\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name &#39;X_test&#39; is not defined"
     ]
    }
   ],
   "source": [
    "X_test_owner = X_test[X_test['type']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;df&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-26-615e6c7d20e1&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[0;32m----&gt; 1\u001b[0;31m \u001b[0mdf_owner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m&#39;type&#39;\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_owner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_owner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m&#39;loan_id&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;loan_date&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;account_date&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;amount&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;duration&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;payments&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;account_district_id&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;client_district_id&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;status&#39;\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf_owner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m&#39;status&#39;\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_owner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m&#39;status&#39;\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m&#39;loan_id&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;loan_date&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;account_date&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;amount&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;duration&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;payments&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;account_district_id&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;client_district_id&#39;\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;df&#39; is not defined"
     ]
    }
   ],
   "source": [
    "df_owner = df[df['type']==1]\n",
    "df_owner = df_owner[['loan_id', 'loan_date', 'account_date', 'amount', 'duration', 'payments', 'account_district_id', 'client_district_id', 'status']]\n",
    "X= df_owner.drop(columns='status')\n",
    "y = df_owner['status'].copy()\n",
    "X_test = X_test[['loan_id', 'loan_date', 'account_date', 'amount', 'duration', 'payments', 'account_district_id', 'client_district_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;df&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-27-1a068af9bc1b&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 2\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name &#39;df&#39; is not defined"
     ]
    }
   ],
   "source": [
    "ax = plt.subplots(figsize=(21, 21))\n",
    "ax = sns.heatmap(df.corr(), annot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}