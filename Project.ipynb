{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "account = pd.read_csv('data/account.csv', delimiter=\";\")\n",
    "card_test = pd.read_csv('data/card_test.csv', delimiter=\";\")\n",
    "card_train = pd.read_csv('data/card_train.csv', delimiter=\";\")\n",
    "client = pd.read_csv('data/client.csv', delimiter=\";\")\n",
    "disp = pd.read_csv('data/disp.csv', delimiter=\";\")\n",
    "district = pd.read_csv('data/district.csv', delimiter=\";\")\n",
    "loan_test = pd.read_csv('data/loan_test.csv', delimiter=\";\")\n",
    "loan_train = pd.read_csv('data/loan_train.csv', delimiter=\";\")\n",
    "trans_test = pd.read_csv('data/trans_test.csv', delimiter=\";\")\n",
    "trans_train = pd.read_csv('data/trans_train.csv', delimiter=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Account\n",
    "- account_id\n",
    "- district_id\n",
    "- date\n",
    "- frequency\n",
    "\n",
    "# Client\n",
    "- client_id\n",
    "- birth_number\n",
    "- district_id\n",
    "\n",
    "# Disposition\n",
    "- disp_id\n",
    "- client_id\n",
    "- account_id\n",
    "- type\n",
    "\n",
    "# Loan\n",
    "- loan_id\n",
    "- account_id\n",
    "- date\n",
    "- amount\n",
    "- duration\n",
    "- payments\n",
    "- status\n",
    "\n",
    "# Transition\n",
    "- trans_id\n",
    "- account_id\n",
    "- date\n",
    "- type\n",
    "- operation\n",
    "- amount_balance\n",
    "- k_symbol\n",
    "- bank\n",
    "- account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameColumns():\n",
    "    account.rename({'date': 'account_date', 'district_id': 'account_district_id'}, axis=1, inplace = True)\n",
    "    client.rename({'district_id': 'client_district_id'}, axis=1, inplace = True)\n",
    "    loan_train.rename({'date': 'loan_date'}, axis=1, inplace = True)\n",
    "    loan_test.rename({'date': 'loan_date'}, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGender(df):\n",
    "    list = []\n",
    "    for row in df.itertuples(index = True):\n",
    "        month = getMonth(row.birth_number)\n",
    "        birth_number = row.birth_number\n",
    "        gender = 'M'\n",
    "        \n",
    "        if(month > 50):\n",
    "            birth_number -= 5000\n",
    "            gender = 'F'\n",
    "            \n",
    "        list.append([row.client_id, birth_number, gender, row.client_district_id])\n",
    "    \n",
    "    return pd.DataFrame(list, columns=['client_id', 'birth_number', 'gender', 'client_district_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonth(date):\n",
    "    remove_day = date //100\n",
    "    month = remove_day % 100\n",
    "    return month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoansInfo(loan_df):\n",
    "    client_processed = getGender(client)\n",
    "    merge1 = pd.merge(client_processed, disp, on ='client_id')\n",
    "    merge2 = pd.merge(merge1, account, on = 'account_id')\n",
    "    loan_info = pd.merge(loan_df, merge2, on = 'account_id')\n",
    "    return loan_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDate(df, name, column):\n",
    "    new_df = df.copy()\n",
    "    new_df[column] = 19000000 + new_df[column]\n",
    "    new_df[column] = pd.to_datetime(new_df[column], format = '%Y%m%d')\n",
    "    new_df.to_csv('data/processed/' + name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "renameColumns()\n",
    "loans = getLoansInfo(loan_train)\n",
    "loans_test = getLoansInfo(loan_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processDates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDates(): \n",
    "    client_processed = getGender(client)\n",
    "    convertToDate(account,'account','account_date')\n",
    "    convertToDate(client_processed,'client','birth_number')\n",
    "    convertToDate(loan_test,'loan_test','loan_date')\n",
    "    convertToDate(loan_train,'loan_train','loan_date')\n",
    "    convertToDate(trans_test,'trans_test','date')\n",
    "    convertToDate(trans_train,'trans_train','date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = loans.copy()\n",
    "for f in df.columns:\n",
    "    if df[f].dtype=='object': \n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(df[f].values))\n",
    "        df[f] = lbl.transform(list(df[f].values))\n",
    "\n",
    "X= df.drop(columns='status')\n",
    "y = df['status'].copy()\n",
    "\n",
    "df_test = loans_test.copy()\n",
    "\n",
    "for f in df_test.columns:\n",
    "    if df_test[f].dtype=='object': \n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(df_test[f].values))\n",
    "        df_test[f] = lbl.transform(list(df_test[f].values))\n",
    "\n",
    "X_test = df_test.drop(columns='status')\n",
    "y_test = df_test['status'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#\ttest_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "\n",
    "def find_best_params_kfold(model, X, y, param_grid, n_iter=10, n_splits=3):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    search = RandomizedSearchCV(model, param_grid, scoring=\"neg_mean_absolute_error\", n_jobs=-1, n_iter=n_iter, cv=kfold, verbose=0, random_state=0)\n",
    "    result = search.fit(X, y)\n",
    "    \n",
    "    report(result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    res = []\n",
    "    res_i = 0\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            res.append([np.multiply(results['mean_test_score'][candidate], -1), \n",
    "                        results['std_test_score'][candidate]])\n",
    "            for key in results['params'][candidate].keys():\n",
    "                res[res_i].append(results['params'][candidate][key])\n",
    "            res_i+=1\n",
    "    \n",
    "    columns = ['Mean absolute error', 'std'] + list(results['params'][candidate].keys())\n",
    "    display(pd.DataFrame(res, columns=columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validationScores(modelName, model, X, y, n_folds=10):\n",
    "    metrics = {'MAE': 'neg_mean_absolute_error', \n",
    "               'RMSE': 'neg_root_mean_squared_error'}\n",
    "    \n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "    scores = cross_validate(model, X, y, cv=kfold, scoring=metrics, n_jobs=-1)\n",
    "\n",
    "    # multiply by -1 because sklearn scoring metrics are negative\n",
    "    mean_mae_score = np.multiply(scores['test_MAE'], -1).mean()\n",
    "    std_mae_score = np.multiply(scores['test_MAE'], -1).std()\n",
    "    mean_rmse_score = np.multiply(scores['test_RMSE'], -1).mean()\n",
    "    std_rmse_score = np.multiply(scores['test_RMSE'], -1).std()\n",
    "\n",
    "    model_score = pd.DataFrame([[mean_mae_score, mean_rmse_score]], \n",
    "                             columns=['MAE', 'RMSE'], index=[modelName])\n",
    "    global models_mean_scores\n",
    "    models_mean_scores = models_mean_scores.append(model_score)\n",
    "\n",
    "    print(str(n_folds) + \" fold Cross validation scores for \" + modelName)\n",
    "    score_df = pd.DataFrame([[mean_mae_score, std_mae_score], \n",
    "                                  [mean_rmse_score, std_rmse_score]], \n",
    "                                 columns=['Mean score', 'std'], \n",
    "                                 index=['MAE', 'RMSE'])\n",
    "    display(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import tree\n",
    "\n",
    "#X_train = df.drop(columns='status')\n",
    "#y_train = loan['status'].copy()\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "#clf = clf.fit(X, y)\n",
    "\n",
    "#X_test = loan_test.drop(columns='status')\n",
    "#y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_loan = {'Id': X_test[\"loan_id\"], 'Predicted': y_test}\n",
    "df = pd.DataFrame(data=predict_loan)\n",
    "df.to_csv('loan_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_depth = range(2, 30, 1)\n",
    "min_samples_split = range(1, 10, 1)\n",
    "\n",
    "param_grid = dict(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "\n",
    "find_best_params_kfold(DecisionTreeClassifier(random_state=0), X, y, param_grid, \n",
    "                       n_iter=50, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_cart = DecisionTreeClassifier(max_depth=2, min_samples_split=9, random_state=0)\n",
    "classifier_cart = classifier_cart.fit(X, y)\n",
    "\n",
    "y_test_cart = classifier_cart.predict(X_test)\n",
    "\n",
    "#df_pred = pd.DataFrame(data={'Id': X_test[\"loan_id\"], 'Predicted': y_test_cart})\n",
    "#df_pred.to_csv('loan_pred_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cart = classifier_cart.predict(X_test)\n",
    "#df_pred = pd.DataFrame(data={'Id': X_test_owner[\"loan_id\"], 'Predicted': y_test_cart})\n",
    "#df_pred.to_csv('loan_pred_3.csv', index=False)\n",
    "y_test_cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "n_estimators = range(50, 1000, 50)\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "find_best_params_kfold(BaggingClassifier(base_estimator=regr_cart,\n",
    "                                        n_jobs=-1, random_state=0), \n",
    "                       X, y, param_grid, n_iter=30, n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_owner = X_test[X_test['type']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_owner = df[df['type']==1]\n",
    "df_owner = df_owner[['loan_id', 'loan_date', 'account_date', 'amount', 'duration', 'payments', 'account_district_id', 'client_district_id', 'status']]\n",
    "X= df_owner.drop(columns='status')\n",
    "y = df_owner['status'].copy()\n",
    "X_test = X_test[['loan_id', 'loan_date', 'account_date', 'amount', 'duration', 'payments', 'account_district_id', 'client_district_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize=(21, 21))\n",
    "ax = sns.heatmap(df.corr(), annot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
